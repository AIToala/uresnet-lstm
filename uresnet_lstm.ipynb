{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "974a9076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from skimage import io, transform as trans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "data_root = 'C:\\\\Users\\\\ai_to\\\\Downloads\\\\RPMR\\\\RPMR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679e919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_conv(in_planes, out_planes):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_planes, out_planes, 3, 1, 1),\n",
    "        nn.BatchNorm2d(out_planes),\n",
    "        nn.ReLU(False),\n",
    "        nn.Conv2d(out_planes, out_planes, 3, 1, 1),\n",
    "        nn.BatchNorm2d(out_planes),\n",
    "        nn.ReLU(False),\n",
    "    )\n",
    "    return conv\n",
    "\n",
    "class Uresnet(nn.Module):\n",
    "    def __init__(self, input_nbr = 3,label_nbr = 2):\n",
    "        super(Uresnet, self).__init__()\n",
    "        \n",
    "        # forward\n",
    "        self.downconv1 = nn.Sequential(\n",
    "            nn.Conv2d(input_nbr, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(False),\n",
    "        )      # No.1 long skip \n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.downconv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 1),\n",
    "            nn.ReLU(False),\n",
    "        )      # No1 resudual block\n",
    "        \n",
    "        self.downconv3 = unet_conv(128, 128) # No2 long skip\n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.downconv4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 1),\n",
    "            nn.ReLU(False),\n",
    "        )      # No2 resudual block\n",
    "        \n",
    "        self.downconv5 = unet_conv(256, 256) # No3 long skip\n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.downconv6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 1),\n",
    "            nn.ReLU(False),\n",
    "        )      # No3 resudual block\n",
    "        \n",
    "        self.downconv7 = unet_conv(512, 512) # No4 long skip\n",
    "\n",
    "        \n",
    "        self.updeconv2 = nn.Sequential(\n",
    "            # nn.ConvTranspose2d(512, 256, 2, 2),\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "        )\n",
    "           \n",
    "        self.upconv3 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, 1),\n",
    "            nn.ReLU(False),\n",
    "        )       # No6 resudual block\n",
    "        self.upconv4 = unet_conv(256, 256)\n",
    "        \n",
    "        self.updeconv3 = nn.Sequential(\n",
    "            # nn.ConvTranspose2d(256, 128, 2, 2),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "        )\n",
    "           \n",
    "        self.upconv5 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 1),\n",
    "            nn.ReLU(False),\n",
    "        )       # No6 resudual block\n",
    "        self.upconv6 = unet_conv(128, 128)\n",
    "        self.updeconv4 = nn.Sequential(\n",
    "            # nn.ConvTranspose2d(128, 64, 2, 2),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=1),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        \n",
    "        self.upconv7 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, 1),\n",
    "            nn.ReLU(False),\n",
    "        \n",
    "        )       # No6 resudual block\n",
    "        self.upconv8 = unet_conv(64, 64)\n",
    "        \n",
    "        self.last = nn.Conv2d(64, label_nbr, 1) \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # encoding\n",
    "        x1 = self.downconv1(x) \n",
    "        x2 = self.maxpool(x1)     \n",
    "        x3 = self.downconv2(x2)\n",
    "        x4 = self.downconv3(x3)      \n",
    "        x4 += x3\n",
    "        x5 = self.maxpool(x4)\n",
    "        \n",
    "        x6 = self.downconv4(x5)\n",
    "        x7 = self.downconv5(x6)\n",
    "        x7 += x6\n",
    "        x8 = self.maxpool(x7)\n",
    "        \n",
    "        x9 = self.downconv6(x8)\n",
    "        x10 = self.downconv7(x9)\n",
    "        x10 += x9\n",
    "\n",
    "        y3 = nn.functional.interpolate(x10, mode='bilinear', scale_factor=2)\n",
    "        y4 = self.updeconv2(y3)\n",
    "        y5 = self.upconv3(torch.cat([y4, x7],1))\n",
    "        y6 = self.upconv4(y5)\n",
    "        y6 += y5\n",
    "        \n",
    "        y6 = nn.functional.interpolate(y6, mode='bilinear', scale_factor=2)\n",
    "        y7 = self.updeconv3(y6)   \n",
    "        y8 = self.upconv5(torch.cat([y7, x4],1))\n",
    "        y9 = self.upconv6(y8)\n",
    "        y9 += y8\n",
    "        \n",
    "        y9 = nn.functional.interpolate(y9, mode='bilinear', scale_factor=2)\n",
    "        y10= self.updeconv4(y9)\n",
    "        y11 = self.upconv7(torch.cat([y10, x1],1))\n",
    "        y12 = self.upconv8(y11)\n",
    "        y12 += y11\n",
    "     \n",
    "        out = self.last(y12)\n",
    "        \n",
    "        return out\n",
    "\n",
    "def uresnet():\n",
    "    net = Uresnet()\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0beda91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv(in_planes, out_planes):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_planes, out_planes, 3, 1, 1),\n",
    "        nn.BatchNorm2d(out_planes),\n",
    "        nn.ReLU(True),\n",
    "        # nn.Dropout(0.2),\n",
    "        nn.Conv2d(out_planes, out_planes, 3, 1, 1),\n",
    "        nn.BatchNorm2d(out_planes),\n",
    "        nn.ReLU(True),\n",
    "    )\n",
    "    return conv\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Unet, self).__init__()\n",
    "        \n",
    "        self.downconv1 = double_conv(3, 64)\n",
    "        self.maxpool = nn.MaxPool2d(2 ,2)\n",
    "        \n",
    "        self.downconv2 = double_conv(64, 128)\n",
    "        self.downconv3 = double_conv(128, 256)\n",
    "        self.downconv4 = double_conv(256, 512)\n",
    "\n",
    "        \n",
    "        self.updeconv2 = nn.ConvTranspose2d(512, 256, 2, 2)\n",
    "        self.upconv2 = double_conv(512, 256)\n",
    "        \n",
    "        self.updeconv3 = nn.ConvTranspose2d(256, 128, 2, 2)\n",
    "        self.upconv3 = double_conv(256, 128)        \n",
    "        \n",
    "        self.updeconv4 = nn.ConvTranspose2d(128, 64, 2, 2)\n",
    "        self.upconv4 = double_conv(128, 64)\n",
    "        \n",
    "        self.out = nn.Conv2d(64, 6, 1)  # 6 is the number of classes need to be segment\n",
    "        \n",
    "        # Weight initialization\n",
    "        for m in self.modules(): \n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            # kaiming\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # encoder\n",
    "        x1 = self.downconv1(x)\n",
    "        x2 = self.maxpool(x1)\n",
    "        \n",
    "        x3 = self.downconv2(x2)\n",
    "        x4 = self.maxpool(x3)\n",
    "        \n",
    "        x5 = self.downconv3(x4)\n",
    "        x6 = self.maxpool(x5)\n",
    "        \n",
    "        x7 = self.downconv4(x6)\n",
    "        \n",
    "        x = self.updeconv2(x7)\n",
    "        # y5 = crop_fun(x5, x)\n",
    "        x = self.upconv2(torch.cat([x, x5],1))\n",
    "        \n",
    "        x = self.updeconv3(x)\n",
    "        # y3 = crop_fun(x3, x)\n",
    "        x = self.upconv3(torch.cat([x, x3],1))\n",
    "        \n",
    "        x = self.updeconv4(x)\n",
    "        # y1 = crop_fun(x1, x)\n",
    "        x = self.upconv4(torch.cat([x, x1],1))\n",
    "        \n",
    "        x = self.out(x)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "    \n",
    "def unet():\n",
    "    net = Unet()\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76b02673",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=64, hidden_size=128, num_layers=1, output_size=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f78801d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UResNetLSTM(nn.Module):\n",
    "    def __init__(self, uresnet_input_nbr=3, uresnet_label_nbr=2, lstm_input_size=64, lstm_hidden_size=128, lstm_num_layers=1, lstm_output_size=3):\n",
    "        super(UResNetLSTM, self).__init__()\n",
    "        \n",
    "        # U-ResNet model\n",
    "        self.uresnet = Uresnet(input_nbr=uresnet_input_nbr, label_nbr=uresnet_label_nbr)\n",
    "        \n",
    "        # LSTM model\n",
    "        self.lstm = LSTMModel(input_size=lstm_input_size, hidden_size=lstm_hidden_size, num_layers=lstm_num_layers, output_size=lstm_output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # U-ResNet forward pass\n",
    "        uresnet_output = self.uresnet(x)\n",
    "        \n",
    "        # LSTM forward pass, using the U-ResNet output as input\n",
    "        lstm_output = self.lstm(uresnet_output)\n",
    "        \n",
    "        #batch_size, _, _ = lstm_output.size()\n",
    "        #lstm_output = lstm_output.view(batch_size, -1, self.lstm.output_size)\n",
    "        lstm_output = lstm_output.unsqueeze(1).repeat(1, 10, 1) \n",
    "\n",
    "        return lstm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9259356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "def normalization(image):\n",
    "    image = image.astype(np.float32)\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "    normalized_image = (image - min_val) / (max_val - min_val)\n",
    "    return normalized_image\n",
    "\n",
    "# Data augmentation\n",
    "def data_augmentation(brightness=0, contrast=0):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomVerticalFlip(1),\n",
    "        transforms.ColorJitter(brightness=brightness, contrast=contrast),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "\n",
    "class PorousMediaDataset(Dataset):\n",
    "    def __init__(self, data_root, transform=None):\n",
    "        self.data_root = data_root\n",
    "        self.transform = transform\n",
    "        self.porous_media_sequences = os.listdir(data_root)\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.porous_media_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence_folder = os.path.join(self.data_root, self.porous_media_sequences[idx])\n",
    "        image_files = sorted(os.listdir(sequence_folder))\n",
    "        sequence_images = []\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(sequence_folder, image_file)\n",
    "            image = io.imread(image_path)\n",
    "            resized_image = trans.resize(image, (200,200), mode='constant', anti_aliasing=True)\n",
    "            normalized_image = normalization(resized_image)\n",
    "            pil_image = Image.fromarray((normalized_image * 255).astype(np.uint8))\n",
    "\n",
    "            sequence_images.append(pil_image)\n",
    "            \n",
    "        # Apply transformations if provided\n",
    "        if self.transform:\n",
    "            sequence_images = [self.transform(image) for image in sequence_images]\n",
    "\n",
    "        # Convert PIL Images to torch tensors\n",
    "        sequence_images = torch.stack(sequence_images)\n",
    "        \n",
    "        return sequence_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e6257bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UResNetDataset(Dataset):\n",
    "    def __init__(self, root_dir, sequence_length=10, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_dir = os.path.join(root_dir, 'samples')\n",
    "        self.image_list = sorted(os.listdir(self.image_dir))\n",
    "        self.sequence_length = sequence_length\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image sequence\n",
    "        image_sequence = []\n",
    "        for i in range(self.sequence_length):\n",
    "            img_name = os.path.join(self.image_dir, self.image_list[idx + i])\n",
    "            image = io.imread(img_name)\n",
    "            resized_image = trans.resize(image, (200,200), mode='constant', anti_aliasing=True)\n",
    "            normalized_image = normalization(resized_image)\n",
    "            pil_image = Image.fromarray((normalized_image * 255).astype(np.uint8))\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            image_sequence.append(image)\n",
    "\n",
    "        # Convert the list of tensors to a single tensor\n",
    "        image_sequence = torch.stack(image_sequence)\n",
    "\n",
    "        return image_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9489f25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformFlipBC = data_augmentation(contrast=0, brightness=0)\n",
    "\n",
    "dataset = UResNetDataset(os.path.join(data_root))\n",
    "#output_dir = 'C:\\\\Users\\\\ai_to\\\\Downloads\\\\RPMR\\\\RPMR\\\\Preprocessed'\n",
    "#dataset.save_transformed_images(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7728d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "valid_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "dataset_length = len(dataset)\n",
    "train_length = int(train_ratio * dataset_length)\n",
    "valid_length = int(valid_ratio * dataset_length)\n",
    "test_length = dataset_length - train_length - valid_length\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_length, valid_length, test_length])\n",
    "\n",
    "# Define data loaders for each split\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "uresnet = Uresnet()\n",
    "seg_criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(uresnet.parameters(), lr=0.001)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "uresnet.to(device)\n",
    "\n",
    "num_epochs = 50\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    uresnet.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch_idx, inputs in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = u_resnet_model(inputs)\n",
    "\n",
    "        # Calculate the unsupervised loss (e.g., Mean Squared Error)\n",
    "        loss = seg_criterion(outputs, inputs)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {total_loss/len(train_loader)}\")\n",
    "\n",
    "    # Validation loop\n",
    "    uresnet.eval()\n",
    "    total_valid_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs in valid_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = uresnet(inputs)\n",
    "            valid_loss = seg_criterion(outputs, inputs)\n",
    "            total_valid_loss += valid_loss.item()\n",
    "\n",
    "    # Print average validation loss for the epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {total_valid_loss/len(valid_loader)}\")\n",
    "    train_losses.append(total_loss/len(train_loader))\n",
    "    valid_losses.append(total_valid_loss/len(valid_loader))\n",
    "# Optionally, save the trained model\n",
    "torch.save(uresnet.state_dict(), \"u_resnet_model.pth\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, num_epochs+1), valid_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c847bc87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc900580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
